{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6xY5h6hyXyyj",
        "outputId": "99d0b773-c146-496b-a0ff-0303e5e20cb6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('Data/WikiQA-train.tsv', sep='\\t')\n",
        "df = df.head(100)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Wrangling\n",
        "Splitting the Dataframe into 3 Columns: (Question, Document, Answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "bDBNSnYxYQJW",
        "outputId": "c6c9a7b1-3ad3-41de-ff26-ef6e11555b7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Document</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>A partly submerged glacier cave on Perito More...</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>In physics , circular motion is a movement of ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how did apollo creed die</td>\n",
              "      <td>Apollo Creed is a fictional character from the...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how long is the term for federal judges</td>\n",
              "      <td>In the United States, the title of federal jud...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how a beretta model 21 pistols magazines works</td>\n",
              "      <td>The Beretta 21A Bobcat is a small pocket-sized...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how a vul works</td>\n",
              "      <td>Variable Universal Life Insurance (often short...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>how an outdoor wood boiler works</td>\n",
              "      <td>The outdoor wood boiler is a variant of the cl...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>how big did girl scout cookie boxes used to be</td>\n",
              "      <td>A mound of Girl Scout cookies. This mound cont...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>how big is the purdue greek system</td>\n",
              "      <td>University Hall Purdue University, located in ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>how big do sebaceous cysts get</td>\n",
              "      <td>A sebaceous cyst () is a term that loosely ref...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>how are pointe shoes made</td>\n",
              "      <td>Modern pointe shoes. The edge of the toe pad, ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>how much is 1 tablespoon of water</td>\n",
              "      <td>This tablespoon has a capacity of about 15 mL....</td>\n",
              "      <td>This tablespoon has a capacity of about 15 mL.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>how much are the harry potter movies worth</td>\n",
              "      <td>Harry Potter is a series of seven fantasy nove...</td>\n",
              "      <td>The series also originated much tie-in merchan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Question  \\\n",
              "0                       how are glacier caves formed?   \n",
              "1   How are the directions of the velocity and for...   \n",
              "2                            how did apollo creed die   \n",
              "3             how long is the term for federal judges   \n",
              "4      how a beretta model 21 pistols magazines works   \n",
              "5                                     how a vul works   \n",
              "6                    how an outdoor wood boiler works   \n",
              "7      how big did girl scout cookie boxes used to be   \n",
              "8                  how big is the purdue greek system   \n",
              "9                      how big do sebaceous cysts get   \n",
              "10                          how are pointe shoes made   \n",
              "11                  how much is 1 tablespoon of water   \n",
              "12         how much are the harry potter movies worth   \n",
              "\n",
              "                                             Document  \\\n",
              "0   A partly submerged glacier cave on Perito More...   \n",
              "1   In physics , circular motion is a movement of ...   \n",
              "2   Apollo Creed is a fictional character from the...   \n",
              "3   In the United States, the title of federal jud...   \n",
              "4   The Beretta 21A Bobcat is a small pocket-sized...   \n",
              "5   Variable Universal Life Insurance (often short...   \n",
              "6   The outdoor wood boiler is a variant of the cl...   \n",
              "7   A mound of Girl Scout cookies. This mound cont...   \n",
              "8   University Hall Purdue University, located in ...   \n",
              "9   A sebaceous cyst () is a term that loosely ref...   \n",
              "10  Modern pointe shoes. The edge of the toe pad, ...   \n",
              "11  This tablespoon has a capacity of about 15 mL....   \n",
              "12  Harry Potter is a series of seven fantasy nove...   \n",
              "\n",
              "                                               Answer  \n",
              "0   A glacier cave is a cave formed within the ice...  \n",
              "1                                                      \n",
              "2                                                      \n",
              "3                                                      \n",
              "4                                                      \n",
              "5                                                      \n",
              "6                                                      \n",
              "7                                                      \n",
              "8                                                      \n",
              "9                                                      \n",
              "10                                                     \n",
              "11     This tablespoon has a capacity of about 15 mL.  \n",
              "12  The series also originated much tie-in merchan...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a new dataframe with four columns\n",
        "new_df = pd.DataFrame(columns=['Question', 'Document', 'Answer'])\n",
        "\n",
        "# Loop through the unique QuestionIDs in the original dataframe\n",
        "for qid in df['QuestionID'].unique():\n",
        "    # Get the first question associated with this QuestionID\n",
        "    first_question = df.loc[df['QuestionID'] == qid, 'Question'].iloc[0]\n",
        "    \n",
        "    # Get all sentences associated with this QuestionID\n",
        "    sentences = df.loc[df['QuestionID'] == qid, 'Sentence']\n",
        "    \n",
        "    # Concatenate all sentences into a single string\n",
        "    concatenated_sentence = ' '.join(sentences)\n",
        "    \n",
        "    # Get the sentence associated with this QuestionID where the Label is 1\n",
        "    answer = df.loc[(df['QuestionID'] == qid) & (df['Label'] == 1), 'Sentence']\n",
        "    \n",
        "    # If there is at least one such row, get the first sentence\n",
        "    if not answer.empty:\n",
        "        answer = answer.iloc[0]\n",
        "    else:\n",
        "        answer = ''\n",
        "    \n",
        "    # Add the QuestionID, first_question, concatenated_sentence, and answer to the new dataframe\n",
        "    new_row = {'Question': first_question, 'Document': concatenated_sentence, 'Answer': answer}\n",
        "    new_df = pd.concat([new_df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "# Print the new dataframe\n",
        "new_df.head(16)\n",
        "               \n",
        "#print(new_df.iloc[0][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HflUEr_7j5cj"
      },
      "outputs": [],
      "source": [
        "# new_df['tokenize'] = ''\n",
        "\n",
        "# for paragraph in new_df.Document:\n",
        "#   token = ['0' for i in range(len(paragraph))]\n",
        "#   if new_df.Answer == '':\n",
        "#     start_index = end_index = -1\n",
        "#     print(1)\n",
        "#   else:\n",
        "#     start_index = paragraph.find(new_df.Answer)\n",
        "#     end_index = start_index + len(new_df.Answer)\n",
        "#     print(start_index)\n",
        "#     print(end_index)\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Labeling each token of the document\n",
        "None: Not part of the answer  \n",
        "S: Start token of the answer  \n",
        "E: End token of the answer  \n",
        "I: Inner token of the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Le2VpZCHsi_g"
      },
      "outputs": [],
      "source": [
        "new_df['labels'] = ''\n",
        "\n",
        "for i in range(len(new_df)):\n",
        "  paragraph = new_df.loc[i, 'Document']\n",
        "  token = ['None' for i in range(len(paragraph))]\n",
        "  if new_df.loc[i, 'Answer'] != '':\n",
        "    start_index = paragraph.find(new_df.loc[i, 'Answer'])\n",
        "    end_index = start_index + len(new_df.loc[i, 'Answer'])\n",
        "    token[start_index] = 'S'\n",
        "    for j in range(start_index+1, end_index):\n",
        "      token[j] = 'I'\n",
        "    token[end_index-1] = 'E'\n",
        "  new_df.at[i, 'labels'] = token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "km6eXNt0smtY",
        "outputId": "317a1bb8-bd53-4fae-cc1c-ef8b548bdf15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Document</th>\n",
              "      <th>Answer</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>A partly submerged glacier cave on Perito More...</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>In physics , circular motion is a movement of ...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how did apollo creed die</td>\n",
              "      <td>Apollo Creed is a fictional character from the...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how long is the term for federal judges</td>\n",
              "      <td>In the United States, the title of federal jud...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how a beretta model 21 pistols magazines works</td>\n",
              "      <td>The Beretta 21A Bobcat is a small pocket-sized...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how a vul works</td>\n",
              "      <td>Variable Universal Life Insurance (often short...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>how an outdoor wood boiler works</td>\n",
              "      <td>The outdoor wood boiler is a variant of the cl...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>how big did girl scout cookie boxes used to be</td>\n",
              "      <td>A mound of Girl Scout cookies. This mound cont...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>how big is the purdue greek system</td>\n",
              "      <td>University Hall Purdue University, located in ...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>how big do sebaceous cysts get</td>\n",
              "      <td>A sebaceous cyst () is a term that loosely ref...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>how are pointe shoes made</td>\n",
              "      <td>Modern pointe shoes. The edge of the toe pad, ...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>how much is 1 tablespoon of water</td>\n",
              "      <td>This tablespoon has a capacity of about 15 mL....</td>\n",
              "      <td>This tablespoon has a capacity of about 15 mL.</td>\n",
              "      <td>[S, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>how much are the harry potter movies worth</td>\n",
              "      <td>Harry Potter is a series of seven fantasy nove...</td>\n",
              "      <td>The series also originated much tie-in merchan...</td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Question  \\\n",
              "0                       how are glacier caves formed?   \n",
              "1   How are the directions of the velocity and for...   \n",
              "2                            how did apollo creed die   \n",
              "3             how long is the term for federal judges   \n",
              "4      how a beretta model 21 pistols magazines works   \n",
              "5                                     how a vul works   \n",
              "6                    how an outdoor wood boiler works   \n",
              "7      how big did girl scout cookie boxes used to be   \n",
              "8                  how big is the purdue greek system   \n",
              "9                      how big do sebaceous cysts get   \n",
              "10                          how are pointe shoes made   \n",
              "11                  how much is 1 tablespoon of water   \n",
              "12         how much are the harry potter movies worth   \n",
              "\n",
              "                                             Document  \\\n",
              "0   A partly submerged glacier cave on Perito More...   \n",
              "1   In physics , circular motion is a movement of ...   \n",
              "2   Apollo Creed is a fictional character from the...   \n",
              "3   In the United States, the title of federal jud...   \n",
              "4   The Beretta 21A Bobcat is a small pocket-sized...   \n",
              "5   Variable Universal Life Insurance (often short...   \n",
              "6   The outdoor wood boiler is a variant of the cl...   \n",
              "7   A mound of Girl Scout cookies. This mound cont...   \n",
              "8   University Hall Purdue University, located in ...   \n",
              "9   A sebaceous cyst () is a term that loosely ref...   \n",
              "10  Modern pointe shoes. The edge of the toe pad, ...   \n",
              "11  This tablespoon has a capacity of about 15 mL....   \n",
              "12  Harry Potter is a series of seven fantasy nove...   \n",
              "\n",
              "                                               Answer  \\\n",
              "0   A glacier cave is a cave formed within the ice...   \n",
              "1                                                       \n",
              "2                                                       \n",
              "3                                                       \n",
              "4                                                       \n",
              "5                                                       \n",
              "6                                                       \n",
              "7                                                       \n",
              "8                                                       \n",
              "9                                                       \n",
              "10                                                      \n",
              "11     This tablespoon has a capacity of about 15 mL.   \n",
              "12  The series also originated much tie-in merchan...   \n",
              "\n",
              "                                               labels  \n",
              "0   [None, None, None, None, None, None, None, Non...  \n",
              "1   [None, None, None, None, None, None, None, Non...  \n",
              "2   [None, None, None, None, None, None, None, Non...  \n",
              "3   [None, None, None, None, None, None, None, Non...  \n",
              "4   [None, None, None, None, None, None, None, Non...  \n",
              "5   [None, None, None, None, None, None, None, Non...  \n",
              "6   [None, None, None, None, None, None, None, Non...  \n",
              "7   [None, None, None, None, None, None, None, Non...  \n",
              "8   [None, None, None, None, None, None, None, Non...  \n",
              "9   [None, None, None, None, None, None, None, Non...  \n",
              "10  [None, None, None, None, None, None, None, Non...  \n",
              "11  [S, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...  \n",
              "12  [None, None, None, None, None, None, None, Non...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne1BRakJv7-7",
        "outputId": "2c0d8116-8d26-44c8-e879-906352a98add"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'S', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'I', 'E', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None', 'None']\n"
          ]
        }
      ],
      "source": [
        "print(new_df.labels[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YQcUzVcGfukf"
      },
      "source": [
        "## TF-IDF "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/vishnuvijay/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# importing necessary libraries for TF-IDF\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords as sw\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Create a new column in the dataframe for the tokenized version of the document\n",
        "new_df['DF'] = \"\"\n",
        "new_df['TFIDF'] = \"\"\n",
        "\n",
        "tknzr = TreebankWordTokenizer()\n",
        "sww = sw.words()\n",
        "\n",
        "# function to tokenize the document and remove stopwords\n",
        "def tokenize(text):\n",
        "  tokens = tknzr.tokenize(text)\n",
        "\n",
        "  # Remove stopwords, commented now for testing\n",
        "  # tokens = [token for token in tokens if token not in sww]\n",
        "  return tokens \n",
        "\n",
        "# looping through the dataframe to tokenize the document, remove punctiations and convert to lowercase\n",
        "for i in range(len(new_df)):\n",
        "  clean_doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', new_df.iloc[i][1])\n",
        "  clean_doc = re.sub(r'\\s+', ' ', clean_doc)\n",
        "  clean_doc = clean_doc.lower()\n",
        "  new_df.at[i, 'Document'] = clean_doc\n",
        "\n",
        "# adding this tokenized version of the document to the dataframe\n",
        "new_df['tokenize'] = new_df['Document'].apply(tokenize)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# looping through the dataframe to calculate the DF and TF-IDF\n",
        "for i in range(len(new_df)):\n",
        "    clean_doc = new_df.iloc[i][6]\n",
        "    DF = {}\n",
        "\n",
        "    for tokenized_doc in clean_doc:\n",
        "        # get each unique word in the doc - and count the number of occurrences in the document\n",
        "        for term in np.unique(tokenized_doc):\n",
        "            try:\n",
        "                DF[term] +=1\n",
        "            except:\n",
        "                DF[term] =1\n",
        "\n",
        "    # add the DF dictionary to the DataFrame as a new column\n",
        "    new_df.at[i, 'DF'] = DF\n",
        "\n",
        "    tf_idf = {}\n",
        "    N = len(clean_doc) \n",
        "    doc_id = 0\n",
        "    for tokenized_doc in clean_doc:\n",
        "        counter = Counter(clean_doc)\n",
        "        total_num_words = len(tokenized_doc) \n",
        "        for term in np.unique(tokenized_doc):\n",
        "            tf = counter[term]/total_num_words\n",
        "            df = DF[term]\n",
        "            idf = math.log(N/(df+1))+1\n",
        "            tf_idf[doc_id, term] = tf*idf\n",
        "\n",
        "    doc_id += 1\n",
        "\n",
        "    # add the TFIDF dictionary to the DataFrame as a new column\n",
        "    new_df.at[i, 'TFIDF'] = tf_idf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## POS Tagger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/vishnuvijay/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/vishnuvijay/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# !pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def pos_tagging(sentence):\n",
        "    words = word_tokenize(sentence)\n",
        "    tagged_words = pos_tag(words)\n",
        "    tagged_words_list, tags_list = zip(*tagged_words)\n",
        "    return tagged_words_list, tags_list\n",
        "\n",
        "new_df['tagged_words'], new_df['tags'] = zip(*new_df['Document'].apply(pos_tagging))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Document</th>\n",
              "      <th>Answer</th>\n",
              "      <th>labels</th>\n",
              "      <th>DF</th>\n",
              "      <th>TFIDF</th>\n",
              "      <th>tokenize</th>\n",
              "      <th>tagged_words</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>a partly submerged glacier cave on perito more...</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'a': 4, 'partly': 1, 'submerged': 1, 'glacier...</td>\n",
              "      <td>{(0, 'a'): 13.872398125886477, (0, 'partly'): ...</td>\n",
              "      <td>[a, partly, submerged, glacier, cave, on, peri...</td>\n",
              "      <td>(a, partly, submerged, glacier, cave, on, peri...</td>\n",
              "      <td>(DT, RB, VBN, NN, NN, IN, NN, NN, VBD, DT, NN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How are the directions of the velocity and for...</td>\n",
              "      <td>in physics circular motion is a movement of an...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'in': 5, 'physics': 1, 'circular': 4, 'motion...</td>\n",
              "      <td>{(0, 'in'): 10.946811314525242, (0, 'physics')...</td>\n",
              "      <td>[in, physics, circular, motion, is, a, movemen...</td>\n",
              "      <td>(in, physics, circular, motion, is, a, movemen...</td>\n",
              "      <td>(IN, NNS, JJ, NN, VBZ, DT, NN, IN, DT, NN, IN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how did apollo creed die</td>\n",
              "      <td>apollo creed is a fictional character from the...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'apollo': 3, 'creed': 5, 'is': 3, 'a': 3, 'fi...</td>\n",
              "      <td>{(0, 'apollo'): 2.397744594586097, (0, 'creed'...</td>\n",
              "      <td>[apollo, creed, is, a, fictional, character, f...</td>\n",
              "      <td>(apollo, creed, is, a, fictional, character, f...</td>\n",
              "      <td>(NNS, VBP, VBZ, DT, JJ, NN, IN, DT, JJ, NNS, R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how long is the term for federal judges</td>\n",
              "      <td>in the united states the title of federal judg...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'in': 6, 'the': 23, 'united': 8, 'states': 8,...</td>\n",
              "      <td>{(0, 'in'): 13.641453882855707, (0, 'the'): 25...</td>\n",
              "      <td>[in, the, united, states, the, title, of, fede...</td>\n",
              "      <td>(in, the, united, states, the, title, of, fede...</td>\n",
              "      <td>(IN, DT, JJ, VBZ, DT, NN, IN, JJ, NN, RB, VBZ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how a beretta model 21 pistols magazines works</td>\n",
              "      <td>the beretta 21a bobcat is a small pocket sized...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'the': 3, 'beretta': 4, '21a': 1, 'bobcat': 1...</td>\n",
              "      <td>{(0, 'the'): 3.4849066497880004, (0, 'beretta'...</td>\n",
              "      <td>[the, beretta, 21a, bobcat, is, a, small, pock...</td>\n",
              "      <td>(the, beretta, 21a, bobcat, is, a, small, pock...</td>\n",
              "      <td>(DT, NN, CD, NN, VBZ, DT, JJ, NN, VBN, JJ, JJ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>how a vul works</td>\n",
              "      <td>variable universal life insurance often shorte...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'variable': 3, 'universal': 3, 'life': 14, 'i...</td>\n",
              "      <td>{(0, 'variable'): 2.131666262580975, (0, 'univ...</td>\n",
              "      <td>[variable, universal, life, insurance, often, ...</td>\n",
              "      <td>(variable, universal, life, insurance, often, ...</td>\n",
              "      <td>(JJ, JJ, NN, NN, RB, VBD, TO, VB, VBZ, DT, NN,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>how an outdoor wood boiler works</td>\n",
              "      <td>the outdoor wood boiler is a variant of the cl...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'the': 3, 'outdoor': 1, 'wood': 2, 'boiler': ...</td>\n",
              "      <td>{(0, 'the'): 2.83258146374831, (0, 'outdoor'):...</td>\n",
              "      <td>[the, outdoor, wood, boiler, is, a, variant, o...</td>\n",
              "      <td>(the, outdoor, wood, boiler, is, a, variant, o...</td>\n",
              "      <td>(DT, JJ, NN, NN, VBZ, DT, NN, IN, DT, JJ, NN, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>how big did girl scout cookie boxes used to be</td>\n",
              "      <td>a mound of girl scout cookies this mound conta...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'a': 2, 'mound': 2, 'of': 6, 'girl': 3, 'scou...</td>\n",
              "      <td>{(0, 'a'): 8.664409020350408, (0, 'mound'): 1....</td>\n",
              "      <td>[a, mound, of, girl, scout, cookies, this, mou...</td>\n",
              "      <td>(a, mound, of, girl, scout, cookies, this, mou...</td>\n",
              "      <td>(DT, NN, IN, NN, NN, NNS, DT, NN, VBZ, CD, NNS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>how big is the purdue greek system</td>\n",
              "      <td>university hall purdue university located in w...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'university': 10, 'hall': 1, 'purdue': 12, 'l...</td>\n",
              "      <td>{(0, 'university'): 4.218875824868201, (0, 'ha...</td>\n",
              "      <td>[university, hall, purdue, university, located...</td>\n",
              "      <td>(university, hall, purdue, university, located...</td>\n",
              "      <td>(NN, NN, JJ, NN, VBN, IN, JJ, NN, NN, VBZ, DT,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>how big do sebaceous cysts get</td>\n",
              "      <td>a sebaceous cyst is a term that loosely refers...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'a': 5, 'sebaceous': 4, 'cyst': 6, 'is': 4, '...</td>\n",
              "      <td>{(0, 'a'): 19.852072327848504, (0, 'sebaceous'...</td>\n",
              "      <td>[a, sebaceous, cyst, is, a, term, that, loosel...</td>\n",
              "      <td>(a, sebaceous, cyst, is, a, term, that, loosel...</td>\n",
              "      <td>(DT, JJ, NN, VBZ, DT, NN, WDT, RB, VBZ, TO, DT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>how are pointe shoes made</td>\n",
              "      <td>modern pointe shoes the edge of the toe pad wh...</td>\n",
              "      <td></td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'modern': 1, 'pointe': 5, 'shoes': 2, 'the': ...</td>\n",
              "      <td>{(0, 'modern'): 0.8723510840995432, (0, 'point...</td>\n",
              "      <td>[modern, pointe, shoes, the, edge, of, the, to...</td>\n",
              "      <td>(modern, pointe, shoes, the, edge, of, the, to...</td>\n",
              "      <td>(JJ, NN, VBZ, DT, NN, IN, DT, NN, NN, WDT, VBZ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>how much is 1 tablespoon of water</td>\n",
              "      <td>this tablespoon has a capacity of about 15 ml ...</td>\n",
              "      <td>This tablespoon has a capacity of about 15 mL.</td>\n",
              "      <td>[S, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
              "      <td>{'this': 1, 'tablespoon': 9, 'has': 1, 'a': 9,...</td>\n",
              "      <td>{(0, 'this'): 1.3407746561970908, (0, 'tablesp...</td>\n",
              "      <td>[this, tablespoon, has, a, capacity, of, about...</td>\n",
              "      <td>(this, tablespoon, has, a, capacity, of, about...</td>\n",
              "      <td>(DT, NN, VBZ, DT, NN, IN, IN, CD, NNS, VBG, NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>how much are the harry potter movies worth</td>\n",
              "      <td>harry potter is a series of seven fantasy nove...</td>\n",
              "      <td>The series also originated much tie-in merchan...</td>\n",
              "      <td>[None, None, None, None, None, None, None, Non...</td>\n",
              "      <td>{'harry': 8, 'potter': 7, 'is': 2, 'a': 4, 'se...</td>\n",
              "      <td>{(0, 'harry'): 7.3822662650247715, (0, 'potter...</td>\n",
              "      <td>[harry, potter, is, a, series, of, seven, fant...</td>\n",
              "      <td>(harry, potter, is, a, series, of, seven, fant...</td>\n",
              "      <td>(NN, NN, VBZ, DT, NN, IN, CD, JJ, NNS, VBN, IN...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Question  \\\n",
              "0                       how are glacier caves formed?   \n",
              "1   How are the directions of the velocity and for...   \n",
              "2                            how did apollo creed die   \n",
              "3             how long is the term for federal judges   \n",
              "4      how a beretta model 21 pistols magazines works   \n",
              "5                                     how a vul works   \n",
              "6                    how an outdoor wood boiler works   \n",
              "7      how big did girl scout cookie boxes used to be   \n",
              "8                  how big is the purdue greek system   \n",
              "9                      how big do sebaceous cysts get   \n",
              "10                          how are pointe shoes made   \n",
              "11                  how much is 1 tablespoon of water   \n",
              "12         how much are the harry potter movies worth   \n",
              "\n",
              "                                             Document  \\\n",
              "0   a partly submerged glacier cave on perito more...   \n",
              "1   in physics circular motion is a movement of an...   \n",
              "2   apollo creed is a fictional character from the...   \n",
              "3   in the united states the title of federal judg...   \n",
              "4   the beretta 21a bobcat is a small pocket sized...   \n",
              "5   variable universal life insurance often shorte...   \n",
              "6   the outdoor wood boiler is a variant of the cl...   \n",
              "7   a mound of girl scout cookies this mound conta...   \n",
              "8   university hall purdue university located in w...   \n",
              "9   a sebaceous cyst is a term that loosely refers...   \n",
              "10  modern pointe shoes the edge of the toe pad wh...   \n",
              "11  this tablespoon has a capacity of about 15 ml ...   \n",
              "12  harry potter is a series of seven fantasy nove...   \n",
              "\n",
              "                                               Answer  \\\n",
              "0   A glacier cave is a cave formed within the ice...   \n",
              "1                                                       \n",
              "2                                                       \n",
              "3                                                       \n",
              "4                                                       \n",
              "5                                                       \n",
              "6                                                       \n",
              "7                                                       \n",
              "8                                                       \n",
              "9                                                       \n",
              "10                                                      \n",
              "11     This tablespoon has a capacity of about 15 mL.   \n",
              "12  The series also originated much tie-in merchan...   \n",
              "\n",
              "                                               labels  \\\n",
              "0   [None, None, None, None, None, None, None, Non...   \n",
              "1   [None, None, None, None, None, None, None, Non...   \n",
              "2   [None, None, None, None, None, None, None, Non...   \n",
              "3   [None, None, None, None, None, None, None, Non...   \n",
              "4   [None, None, None, None, None, None, None, Non...   \n",
              "5   [None, None, None, None, None, None, None, Non...   \n",
              "6   [None, None, None, None, None, None, None, Non...   \n",
              "7   [None, None, None, None, None, None, None, Non...   \n",
              "8   [None, None, None, None, None, None, None, Non...   \n",
              "9   [None, None, None, None, None, None, None, Non...   \n",
              "10  [None, None, None, None, None, None, None, Non...   \n",
              "11  [S, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...   \n",
              "12  [None, None, None, None, None, None, None, Non...   \n",
              "\n",
              "                                                   DF  \\\n",
              "0   {'a': 4, 'partly': 1, 'submerged': 1, 'glacier...   \n",
              "1   {'in': 5, 'physics': 1, 'circular': 4, 'motion...   \n",
              "2   {'apollo': 3, 'creed': 5, 'is': 3, 'a': 3, 'fi...   \n",
              "3   {'in': 6, 'the': 23, 'united': 8, 'states': 8,...   \n",
              "4   {'the': 3, 'beretta': 4, '21a': 1, 'bobcat': 1...   \n",
              "5   {'variable': 3, 'universal': 3, 'life': 14, 'i...   \n",
              "6   {'the': 3, 'outdoor': 1, 'wood': 2, 'boiler': ...   \n",
              "7   {'a': 2, 'mound': 2, 'of': 6, 'girl': 3, 'scou...   \n",
              "8   {'university': 10, 'hall': 1, 'purdue': 12, 'l...   \n",
              "9   {'a': 5, 'sebaceous': 4, 'cyst': 6, 'is': 4, '...   \n",
              "10  {'modern': 1, 'pointe': 5, 'shoes': 2, 'the': ...   \n",
              "11  {'this': 1, 'tablespoon': 9, 'has': 1, 'a': 9,...   \n",
              "12  {'harry': 8, 'potter': 7, 'is': 2, 'a': 4, 'se...   \n",
              "\n",
              "                                                TFIDF  \\\n",
              "0   {(0, 'a'): 13.872398125886477, (0, 'partly'): ...   \n",
              "1   {(0, 'in'): 10.946811314525242, (0, 'physics')...   \n",
              "2   {(0, 'apollo'): 2.397744594586097, (0, 'creed'...   \n",
              "3   {(0, 'in'): 13.641453882855707, (0, 'the'): 25...   \n",
              "4   {(0, 'the'): 3.4849066497880004, (0, 'beretta'...   \n",
              "5   {(0, 'variable'): 2.131666262580975, (0, 'univ...   \n",
              "6   {(0, 'the'): 2.83258146374831, (0, 'outdoor'):...   \n",
              "7   {(0, 'a'): 8.664409020350408, (0, 'mound'): 1....   \n",
              "8   {(0, 'university'): 4.218875824868201, (0, 'ha...   \n",
              "9   {(0, 'a'): 19.852072327848504, (0, 'sebaceous'...   \n",
              "10  {(0, 'modern'): 0.8723510840995432, (0, 'point...   \n",
              "11  {(0, 'this'): 1.3407746561970908, (0, 'tablesp...   \n",
              "12  {(0, 'harry'): 7.3822662650247715, (0, 'potter...   \n",
              "\n",
              "                                             tokenize  \\\n",
              "0   [a, partly, submerged, glacier, cave, on, peri...   \n",
              "1   [in, physics, circular, motion, is, a, movemen...   \n",
              "2   [apollo, creed, is, a, fictional, character, f...   \n",
              "3   [in, the, united, states, the, title, of, fede...   \n",
              "4   [the, beretta, 21a, bobcat, is, a, small, pock...   \n",
              "5   [variable, universal, life, insurance, often, ...   \n",
              "6   [the, outdoor, wood, boiler, is, a, variant, o...   \n",
              "7   [a, mound, of, girl, scout, cookies, this, mou...   \n",
              "8   [university, hall, purdue, university, located...   \n",
              "9   [a, sebaceous, cyst, is, a, term, that, loosel...   \n",
              "10  [modern, pointe, shoes, the, edge, of, the, to...   \n",
              "11  [this, tablespoon, has, a, capacity, of, about...   \n",
              "12  [harry, potter, is, a, series, of, seven, fant...   \n",
              "\n",
              "                                         tagged_words  \\\n",
              "0   (a, partly, submerged, glacier, cave, on, peri...   \n",
              "1   (in, physics, circular, motion, is, a, movemen...   \n",
              "2   (apollo, creed, is, a, fictional, character, f...   \n",
              "3   (in, the, united, states, the, title, of, fede...   \n",
              "4   (the, beretta, 21a, bobcat, is, a, small, pock...   \n",
              "5   (variable, universal, life, insurance, often, ...   \n",
              "6   (the, outdoor, wood, boiler, is, a, variant, o...   \n",
              "7   (a, mound, of, girl, scout, cookies, this, mou...   \n",
              "8   (university, hall, purdue, university, located...   \n",
              "9   (a, sebaceous, cyst, is, a, term, that, loosel...   \n",
              "10  (modern, pointe, shoes, the, edge, of, the, to...   \n",
              "11  (this, tablespoon, has, a, capacity, of, about...   \n",
              "12  (harry, potter, is, a, series, of, seven, fant...   \n",
              "\n",
              "                                                 tags  \n",
              "0   (DT, RB, VBN, NN, NN, IN, NN, NN, VBD, DT, NN,...  \n",
              "1   (IN, NNS, JJ, NN, VBZ, DT, NN, IN, DT, NN, IN,...  \n",
              "2   (NNS, VBP, VBZ, DT, JJ, NN, IN, DT, JJ, NNS, R...  \n",
              "3   (IN, DT, JJ, VBZ, DT, NN, IN, JJ, NN, RB, VBZ,...  \n",
              "4   (DT, NN, CD, NN, VBZ, DT, JJ, NN, VBN, JJ, JJ,...  \n",
              "5   (JJ, JJ, NN, NN, RB, VBD, TO, VB, VBZ, DT, NN,...  \n",
              "6   (DT, JJ, NN, NN, VBZ, DT, NN, IN, DT, JJ, NN, ...  \n",
              "7   (DT, NN, IN, NN, NN, NNS, DT, NN, VBZ, CD, NNS...  \n",
              "8   (NN, NN, JJ, NN, VBN, IN, JJ, NN, NN, VBZ, DT,...  \n",
              "9   (DT, JJ, NN, VBZ, DT, NN, WDT, RB, VBZ, TO, DT...  \n",
              "10  (JJ, NN, VBZ, DT, NN, IN, DT, NN, NN, WDT, VBZ...  \n",
              "11  (DT, NN, VBZ, DT, NN, IN, IN, CD, NNS, VBG, NN...  \n",
              "12  (NN, NN, VBZ, DT, NN, IN, CD, JJ, NNS, VBN, IN...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m Tokenizer\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequences\n\u001b[1;32m      6\u001b[0m \u001b[39m# Sample dataframe\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sample dataframe\n",
        "new_df = pd.DataFrame({\n",
        "    'Question': ['What is your name?', 'How old are you?', 'Where are you from?', 'What is your favorite color?']\n",
        "})\n",
        "\n",
        "# Tokenize the questions\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(new_df['Question'])\n",
        "new_df['Question_tokenized'] = tokenizer.texts_to_sequences(new_df['Question'])\n",
        "\n",
        "# Get the maximum length of all the questions in the 'Question' column of the dataframe\n",
        "max_length = max(len(question) for question in new_df['Question_tokenized'])\n",
        "\n",
        "# Pad the sequence based on the max length defined, to make sure the list of sequences are of same length\n",
        "def pad_sequence(seq_list, max_length, index_dict):\n",
        "    res = []\n",
        "    for seq in seq_list:\n",
        "        temp = seq[:]\n",
        "        # Pad the sequence with zeros if its length is less than max_length\n",
        "        temp += [index_dict['[PAD]']] * (max_length - len(seq))\n",
        "        res.append(temp)\n",
        "    return np.array(res)\n",
        "\n",
        "# Add the Question_padded column with the padded sequences\n",
        "word2index = tokenizer.word_index\n",
        "word2index['[PAD]'] = 0 # Add the '[PAD]' token to the word2index dictionary\n",
        "new_df['Question_padded'] = pad_sequence(new_df['Question_tokenized'], max_length, word2index)\n",
        "\n",
        "print(new_df)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'partly', 'submerge', 'glacier', 'cave', 'on', 'perito', 'moreno', 'glacier', 'the', 'ice', 'facade', 'be', 'approximately', '60', 'm', 'high', 'ice', 'formation', 'in', 'the', 'titlis', 'glacier', 'cave', 'a', 'glacier', 'cave', 'be', 'a', 'cave', 'form', 'within', 'the', 'ice', 'of', 'a', 'glacier', 'glacier', 'cave', 'be', 'often', 'call', 'ice', 'cave', 'but', 'this', 'term', 'be', 'properly', 'use', 'to', 'describe', 'bedrock', 'cave', 'that', 'contain', 'year', 'round', 'ice']\n",
            "['in', 'physic', 'circular', 'motion', 'be', 'a', 'movement', 'of', 'an', 'object', 'along', 'the', 'circumference', 'of', 'a', 'circle', 'or', 'rotation', 'along', 'a', 'circular', 'path', 'it', 'can', 'be', 'uniform', 'with', 'constant', 'angular', 'rate', 'of', 'rotation', 'and', 'constant', 'speed', 'or', 'non', 'uniform', 'with', 'a', 'change', 'rate', 'of', 'rotation', 'the', 'rotation', 'around', 'a', 'fixed', 'axis', 'of', 'a', 'three', 'dimensional', 'body', 'involve', 'circular', 'motion', 'of', 'it', 'part', 'the', 'equation', 'of', 'motion', 'describe', 'the', 'movement', 'of', 'the', 'center', 'of', 'mass', 'of', 'a', 'body', 'examples', 'of', 'circular', 'motion', 'include', 'an', 'artificial', 'satellite', 'orbit', 'the', 'earth', 'at', 'constant', 'height', 'a', 'stone', 'which', 'be', 'tie', 'to', 'a', 'rope', 'and', 'be', 'be', 'swing', 'in', 'circle', 'a', 'car', 'turn', 'through', 'a', 'curve', 'in', 'a', 'race', 'track', 'an', 'electron', 'move', 'perpendicular', 'to', 'a', 'uniform', 'magnetic', 'field', 'and', 'a', 'gear', 'turning', 'inside', 'a', 'mechanism', 'since', 'the', 'object', 's', 'velocity', 'vector', 'be', 'constantly', 'change', 'direction', 'the', 'move', 'object', 'be', 'undergo', 'acceleration', 'by', 'a', 'centripetal', 'force', 'in', 'the', 'direction', 'of', 'the', 'center', 'of', 'rotation', 'without', 'this', 'acceleration', 'the', 'object', 'would', 'move', 'in', 'a', 'straight', 'line', 'accord', 'to', 'newton', 's', 'law', 'of', 'motion']\n",
            "['apollo', 'creed', 'be', 'a', 'fictional', 'character', 'from', 'the', 'rocky', 'film', 'initially', 'portray', 'a', 'the', 'undisputed', 'heavyweight', 'champion', 'of', 'the', 'world', 'he', 'be', 'play', 'by', 'carl', 'weather', 'creed', 'have', 'multiple', 'nickname', 'include', 'the', 'master', 'of', 'disaster', 'the', 'king', 'of', 'sting', 'the', 'dance', 'destroyer', 'the', 'prince', 'of', 'punch', 'the', 'one', 'and', 'only', 'and', 'the', 'count', 'of', 'monte', 'fisto', 'urban', 'legend', 'state', 'that', 'apollo', 'creed', 's', 'name', 'be', 'a', 'wordplay', 'on', 'the', 'apostle', 'creed', 'a', 'statement', 'of', 'belief', 'use', 'in', 'christian', 'church', 'all', 'of', 'apollo', 's', 'championship', 'fight', 'be', 'schedule', 'for', 'the', '15', 'round', 'distance', 'championship', 'fight', 'do', 'not', 'convert', 'from', '15', 'round', 'to', '12', 'round', 'until', '1987', 'rocky', 'balboa', 'be', 'often', 'wrongly', 'credit', 'with', 'popularize', 'the', 'red', 'white', 'and', 'blue', 'trunk', 'creed', 'be', 'the', 'first', 'man', 'to', 'wear', 'them', 'latterly', 'wear', 'by', 'rocky', 'balboa', 'in', 'the', '3rd', 'and', '4th', 'installment', 'and', 'finally', 'by', 'tommy', 'the', 'machine', 'gunn', 'tommy', 'morrison', 'in', 'the', '5th', 'installment', 'although', 'normally', 'he', 'wear', 'red', 'and', 'white', 'a', 'see', 'in', 'rocky', 'ii', 'balboa', 's', 'signature', 'color', 'be', 'black', 'and', 'gold', 'color', 'he', 'use', 'in', 'the', 'late', 'movie']\n",
            "['in', 'the', 'united', 'state', 'the', 'title', 'of', 'federal', 'judge', 'usually', 'mean', 'a', 'judge', 'appoint', 'by', 'the', 'president', 'of', 'the', 'united', 'state', 'and', 'confirm', 'by', 'the', 'united', 'state', 'senate', 'pursuant', 'to', 'the', 'appointment', 'clause', 'in', 'article', 'ii', 'of', 'the', 'united', 'state', 'constitution', 'in', 'addition', 'to', 'the', 'supreme', 'court', 'of', 'the', 'united', 'state', 'whose', 'existence', 'and', 'some', 'aspect', 'of', 'whose', 'jurisdiction', 'be', 'beyond', 'the', 'constitutional', 'power', 'of', 'congress', 'to', 'alter', 'act', 'of', 'congress', 'have', 'establish', '13', 'court', 'of', 'appeal', 'also', 'call', 'circuit', 'court', 'with', 'appellate', 'jurisdiction', 'over', 'different', 'region', 'of', 'the', 'united', 'state', 'and', '94', 'united', 'state', 'district', 'court', 'every', 'judge', 'appoint', 'to', 'such', 'a', 'court', 'may', 'be', 'categorize', 'a', 'a', 'federal', 'judge', 'such', 'position', 'include', 'the', 'chief', 'justice', 'and', 'associate', 'justice', 'of', 'the', 'supreme', 'court', 'circuit', 'judge', 'of', 'the', 'court', 'of', 'appeal', 'and', 'district', 'judge', 'of', 'the', 'united', 'state', 'district', 'court', 'all', 'of', 'these', 'judge', 'describe', 'thus', 'far', 'be', 'refer', 'to', 'sometimes', 'a', 'article', 'iii', 'judge', 'because', 'they', 'exercise', 'the', 'judicial', 'power', 'vest', 'in', 'the', 'judicial', 'branch', 'of', 'the', 'federal', 'government', 'by', 'article', 'iii', 'of', 'the', 'u', 's', 'constitution', 'in', 'addition', 'judge', 'of', 'the', 'court', 'of', 'international', 'trade', 'exercise', 'judicial', 'power', 'pursuant', 'to', 'article', 'iii', 'other', 'judge', 'serve', 'in', 'the', 'federal', 'court', 'include', 'magistrate', 'judge', 'and', 'bankruptcy', 'judge', 'be', 'also', 'sometimes', 'refer', 'to', 'a', 'federal', 'judge', 'however', 'they', 'be', 'neither', 'appoint', 'by', 'the', 'president', 'nor', 'confirm', 'by', 'the', 'senate', 'and', 'their', 'power', 'derives', 'from', 'article', 'i', 'instead', 'see', 'article', 'i', 'and', 'article', 'iii', 'tribunal']\n",
            "['the', 'beretta', '21a', 'bobcat', 'be', 'a', 'small', 'pocket', 'size', 'semi', 'automatic', 'pistol', 'design', 'by', 'beretta', 'in', 'italy', 'production', 'begin', 'in', 'late', '1984', 'solely', 'in', 'the', 'beretta', 'u', 's', 'a', 'facility', 'in', 'accokeek', 'maryland', 'it', 'be', 'a', 'further', 'development', 'of', 'the', 'beretta', 'model', '20', 'whose', 'production', 'end', 'in', '1985']\n",
            "['variable', 'universal', 'life', 'insurance', 'often', 'shorten', 'to', 'vul', 'be', 'a', 'type', 'of', 'life', 'insurance', 'that', 'build', 'a', 'cash', 'value', 'in', 'a', 'vul', 'the', 'cash', 'value', 'can', 'be', 'invest', 'in', 'a', 'wide', 'variety', 'of', 'separate', 'account', 'similar', 'to', 'mutual', 'fund', 'and', 'the', 'choice', 'of', 'which', 'of', 'the', 'available', 'separate', 'account', 'to', 'use', 'be', 'entirely', 'up', 'to', 'the', 'contract', 'owner', 'the', 'variable', 'component', 'in', 'the', 'name', 'refer', 'to', 'this', 'ability', 'to', 'invest', 'in', 'separate', 'account', 'whose', 'value', 'vary', 'they', 'vary', 'because', 'they', 'be', 'invest', 'in', 'stock', 'and', 'or', 'bond', 'market', 'the', 'universal', 'component', 'in', 'the', 'name', 'refers', 'to', 'the', 'flexibility', 'the', 'owner', 'have', 'in', 'make', 'premium', 'payment', 'the', 'premium', 'can', 'vary', 'from', 'nothing', 'in', 'a', 'give', 'month', 'up', 'to', 'maximum', 'define', 'by', 'the', 'internal', 'revenue', 'code', 'for', 'life', 'insurance', 'this', 'flexibility', 'be', 'in', 'contrast', 'to', 'whole', 'life', 'insurance', 'that', 'have', 'fix', 'premium', 'payment', 'that', 'typically', 'can', 'not', 'be', 'miss', 'without', 'lapse', 'the', 'policy', 'although', 'one', 'may', 'exercise', 'an', 'automatic', 'premium', 'loan', 'feature', 'or', 'surrender', 'dividend', 'to', 'pay', 'a', 'whole', 'life', 'premium', 'variable', 'universal', 'life', 'be', 'a', 'type', 'of', 'permanent', 'life', 'insurance', 'because', 'the', 'death', 'benefit', 'will', 'be', 'pay', 'if', 'the', 'insured', 'die', 'any', 'time', 'as', 'long', 'a', 'there', 'be', 'sufficient', 'cash', 'value', 'to', 'pay', 'the', 'cost', 'of', 'insurance', 'in', 'the', 'policy', 'with', 'most', 'if', 'not', 'all', 'vuls', 'unlike', 'whole', 'life', 'there', 'be', 'no', 'endowment', 'age', 'the', 'age', 'at', 'which', 'the', 'cash', 'value', 'equal', 'the', 'death', 'benefit', 'amount', 'which', 'for', 'whole', 'life', 'be', 'typically', '100', 'this', 'be', 'yet', 'another', 'key', 'advantage', 'of', 'vul', 'over', 'whole', 'life', 'with', 'a', 'typical', 'whole', 'life', 'policy', 'the', 'death', 'benefit', 'be', 'limit', 'to', 'the', 'face', 'amount', 'specify', 'in', 'the', 'policy', 'and', 'at', 'endowment', 'age', 'the', 'face', 'amount', 'be', 'all', 'that', 'be', 'pay', 'out', 'thus', 'with', 'either', 'death', 'or', 'endowment', 'the', 'insurance', 'company', 'keep', 'any', 'cash', 'value', 'build', 'up', 'over', 'the', 'year', 'however', 'some', 'participate', 'whole', 'life', 'policy', 'offer', 'rider', 'which', 'specify', 'that', 'any', 'dividend', 'pay', 'on', 'the', 'policy', 'be', 'use', 'to', 'purchase', 'pay', 'up', 'addition', 'to', 'the', 'policy', 'which', 'increase', 'both', 'the', 'cash', 'value', 'and', 'the', 'death', 'benefit', 'over', 'time', 'if', 'investment', 'make', 'in', 'the', 'separate', 'account', 'out', 'perform', 'the', 'general', 'account', 'of', 'the', 'insurance', 'company', 'a', 'high', 'rate', 'of', 'return', 'can', 'occur', 'than', 'the', 'fixed', 'rate', 'of', 'return', 'typical', 'for', 'whole', 'life', 'the', 'combination', 'over', 'the', 'year', 'of', 'no', 'endowment', 'age', 'continually', 'increase', 'death', 'benefit', 'and', 'if', 'a', 'high', 'rate', 'of', 'return', 'be', 'earn', 'in', 'the', 'separate', 'account', 'of', 'a', 'vul', 'policy', 'this', 'could', 'result', 'in', 'high', 'value', 'to', 'the', 'owner', 'or', 'beneficiary', 'than', 'that', 'of', 'a', 'whole', 'life', 'policy', 'with', 'the', 'same', 'amount', 'of', 'money', 'pay', 'in', 'a', 'premium']\n",
            "['the', 'outdoor', 'wood', 'boiler', 'be', 'a', 'variant', 'of', 'the', 'classic', 'wood', 'stove', 'adapt', 'for', 'set', 'up', 'outdoors', 'while', 'still', 'transfer', 'the', 'heat', 'to', 'interior', 'building']\n",
            "['a', 'mound', 'of', 'girl', 'scout', 'cooky', 'this', 'mound', 'contain', '74', 'box', 'of', 'cooky', 'girl', 'scout', 'cooky', 'be', 'cooky', 'sell', 'by', 'girl', 'scout', 'of', 'the', 'usa', 'gsusa', 'a', 'one', 'of', 'it', 'major', 'fundraiser', 'for', 'local', 'scout', 'unit', 'member', 'of', 'the', 'gsusa', 'have', 'be', 'sell', 'cooky', 'since', '1917', 'to', 'raise', 'fund', 'girl', 'who', 'participate', 'can', 'earn', 'prize', 'for', 'their', 'effort', 'there', 'be', 'also', 'unit', 'incentive', 'if', 'the', 'unit', 'a', 'a', 'whole', 'do', 'well', 'a', 'of', '2007', 'sale', 'be', 'estimate', 'at', 'about', '200', 'million', 'box', 'per', 'year']\n",
            "['university', 'hall', 'purdue', 'university', 'locate', 'in', 'west', 'lafayette', 'indiana', 'be', 'the', 'flagship', 'university', 'of', 'the', 'six', 'campus', 'purdue', 'university', 'system', 'purdue', 'be', 'found', 'on', 'may', '6', '1869', 'a', 'a', 'land', 'grant', 'university', 'when', 'the', 'indiana', 'general', 'assembly', 'take', 'advantage', 'of', 'the', 'morrill', 'act', 'accept', 'a', 'donation', 'of', 'land', 'and', 'money', 'from', 'lafayette', 'businessman', 'john', 'purdue', 'to', 'establish', 'a', 'college', 'of', 'science', 'technology', 'and', 'agriculture', 'in', 'his', 'name', 'the', 'first', 'class', 'be', 'hold', 'on', 'september', '16', '1874', 'with', 'six', 'instructor', 'and', '39', 'student', 'today', 'purdue', 'be', 'a', 'member', 'of', 'the', 'big', 'ten', 'conference', 'and', 'be', 'a', 'well', 'know', 'world', 'class', 'research', 'institution', 'purdue', 'enroll', 'the', 'second', 'large', 'student', 'body', 'of', 'any', 'university', 'in', 'indiana', 'as', 'well', 'a', 'the', 'fourth', 'large', 'international', 'student', 'population', 'of', 'any', 'university', 'in', 'the', 'united', 'state', 'purdue', 'offer', 'both', 'undergraduate', 'and', 'graduate', 'program', 'in', 'over', '211', 'major', 'area', 'of', 'study', 'and', 'be', 'well', 'know', 'for', 'it', 'competitive', 'engineering', 'curriculum', 'the', 'university', 'have', 'also', 'be', 'highly', 'influential', 'in', 'america', 's', 'history', 'of', 'aviation', 'have', 'establish', 'the', 'first', 'college', 'credit', 'offer', 'in', 'flight', 'train', 'the', 'first', 'four', 'year', 'bachelor', 's', 'degree', 'in', 'aviation', 'and', 'the', 'first', 'university', 'airport', 'purdue', 'university', 'airport', 'purdue', 's', 'aviation', 'technology', 'program', 'remain', 'one', 'of', 'the', 'most', 'competitive', 'aviation', 'specific', 'program', 'in', 'the', 'world', 'in', 'the', 'mid', '20th', 'century', 'purdue', 's', 'aviation', 'program', 'expand', 'to', 'encompass', 'advanced', 'spaceflight', 'technology', 'give', 'rise', 'to', 'purdue', 's', 'nickname', 'cradle', 'of', 'astronaut', 'twenty', 'three', 'purdue', 'graduate', 'have', 'go', 'on', 'to', 'become', 'astronauts', 'include', 'gus', 'grissom', 'one', 'of', 'the', 'original', 'mercury', 'seven', 'astronaut', 'neil', 'armstrong', 'the', 'first', 'person', 'to', 'walk', 'on', 'the', 'moon', 'and', 'eugene', 'cernan', 'the', 'most', 'recent', 'person', 'to', 'walk', 'on', 'the', 'moon']\n",
            "['a', 'sebaceous', 'cyst', 'be', 'a', 'term', 'that', 'loosely', 'refer', 'to', 'either', 'epidermoid', 'cyst', 'also', 'know', 'a', 'epidermal', 'cyst', 'l72', '0', 'or', 'pilar', 'cyst', 'also', 'know', 'a', 'trichilemmal', 'cyst', 'l72', '1', 'because', 'an', 'epidermoid', 'cyst', 'originates', 'in', 'the', 'epidermis', 'and', 'a', 'pilar', 'cyst', 'originates', 'from', 'hair', 'follicle', 'by', 'definition', 'neither', 'type', 'of', 'cyst', 'be', 'strictly', 'a', 'sebaceous', 'cyst', 'the', 'name', 'be', 'regard', 'a', 'a', 'misnomer', 'a', 'the', 'fatty', 'white', 'semi', 'solid', 'material', 'in', 'both', 'of', 'these', 'cyst', 'entity', 'be', 'not', 'sebum', 'but', 'keratin', 'furthermore', 'under', 'the', 'microscope', 'neither', 'entity', 'contain', 'sebaceous', 'gland', 'in', 'practice', 'however', 'the', 'term', 'be', 'often', 'use', 'interchangeably', 'true', 'sebaceous', 'cyst', 'be', 'relatively', 'rare', 'and', 'be', 'know', 'a', 'steatocystoma', 'or', 'if', 'multiple', 'a', 'steatocystoma', 'multiplex']\n",
            "['modern', 'pointe', 'shoe', 'the', 'edge', 'of', 'the', 'toe', 'pad', 'which', 'be', 'insert', 'between', 'the', 'foot', 'and', 'toe', 'box', 'for', 'cushion', 'can', 'be', 'see', 'on', 'the', 'right', 'foot', 'a', 'pointe', 'shoe', 'be', 'a', 'type', 'of', 'shoe', 'wear', 'by', 'ballet', 'dancer', 'when', 'perform', 'pointe', 'work', 'pointe', 'shoe', 'develop', 'from', 'the', 'desire', 'for', 'dancer', 'to', 'appear', 'weightless', 'and', 'sylph', 'like', 'and', 'have', 'evolve', 'to', 'enable', 'dancer', 'to', 'dance', 'en', 'pointe', 'on', 'the', 'tip', 'of', 'their', 'toe', 'for', 'extended', 'period', 'of', 'time', 'they', 'be', 'normally', 'wear', 'by', 'female', 'dancer', 'though', 'male', 'dancer', 'may', 'wear', 'them', 'for', 'unorthodox', 'role', 'such', 'a', 'the', 'ugly', 'stepsister', 'in', 'cinderella', 'bottom', 'in', 'a', 'midsummer', 'night', 's', 'dream', 'or', 'men', 'perform', 'a', 'woman', 'in', 'dance', 'company', 'such', 'a', 'le', 'ballet', 'trockadero', 'and', 'grandiva', 'they', 'be', 'manufacture', 'in', 'a', 'variety', 'of', 'color', 'most', 'commonly', 'in', 'shade', 'of', 'light', 'pink']\n",
            "['this', 'tablespoon', 'have', 'a', 'capacity', 'of', 'about', '15', 'ml', 'measure', 'spoon', 'in', 'the', 'u', 'and', 'part', 'of', 'canada', 'a', 'tablespoon', 'be', 'the', 'large', 'type', 'of', 'spoon', 'use', 'for', 'eat', 'from', 'a', 'bowl', 'in', 'the', 'uk', 'europe', 'and', 'most', 'commonwealth', 'country', 'a', 'tablespoon', 'be', 'a', 'type', 'of', 'large', 'spoon', 'usually', 'use', 'for', 'serve', 'in', 'country', 'where', 'a', 'tablespoon', 'be', 'a', 'serve', 'spoon', 'the', 'near', 'equivalent', 'to', 'the', 'u', 'tablespoon', 'be', 'either', 'the', 'dessert', 'spoon', 'or', 'the', 'soup', 'spoon', 'a', 'tablespoonful', 'nominally', 'the', 'capacity', 'of', 'one', 'tablespoon', 'be', 'commonly', 'use', 'a', 'a', 'measure', 'of', 'volume', 'in', 'cook', 'it', 'be', 'abbreviate', 'a', 't', 'tb', 'tb', 'tbsp', 'tblsp', 'or', 'tblspn', 'the', 'capacity', 'of', 'ordinary', 'tablespoon', 'be', 'not', 'regulate', 'by', 'law', 'and', 'be', 'subject', 'to', 'considerable', 'variation', 'in', 'the', 'usa', 'one', 'tablespoon', 'measurement', 'unit', 'be', 'approximately', '15', 'ml', 'the', 'capacity', 'of', 'an', 'actual', 'tablespoon', 'din', 'utensil', 'range', 'from', '7', 'ml', 'to', '14', 'ml', 'in', 'australia', 'one', 'tablespoon', 'measurement', 'unit', 'be', '20', 'ml']\n",
            "['harry', 'potter', 'be', 'a', 'series', 'of', 'seven', 'fantasy', 'novel', 'write', 'by', 'the', 'british', 'author', 'j', 'k', 'rowling', 'the', 'book', 'chronicle', 'the', 'adventure', 'of', 'a', 'wizard', 'harry', 'potter', 'and', 'his', 'friend', 'ronald', 'weasley', 'and', 'hermione', 'granger', 'all', 'of', 'whom', 'be', 'student', 'at', 'hogwarts', 'school', 'of', 'witchcraft', 'and', 'wizardry', 'the', 'main', 'story', 'arc', 'concern', 'harry', 's', 'quest', 'to', 'overcome', 'the', 'dark', 'wizard', 'lord', 'voldemort', 'whose', 'aim', 'be', 'to', 'become', 'immortal', 'conquer', 'the', 'wizarding', 'world', 'subjugate', 'non', 'magical', 'people', 'and', 'destroy', 'all', 'those', 'who', 'stand', 'in', 'his', 'way', 'especially', 'harry', 'potter', 'since', 'the', 'release', 'of', 'the', 'first', 'novel', 'harry', 'potter', 'and', 'the', 'philosopher', 's', 'stone', 'on', '30', 'june', '1997', 'the', 'book', 'have', 'gain', 'immense', 'popularity', 'critical', 'acclaim', 'and', 'commercial', 'success', 'worldwide', 'the', 'series', 'have', 'also', 'have', 'some', 'share', 'of', 'criticism', 'include', 'concern', 'for', 'the', 'increasingly', 'dark', 'tone', 'the', 'book', 'series', 'have', 'sell', 'about', '450', 'million', 'copy', 'make', 'it', 'the', 'best', 'selling', 'book', 'series', 'in', 'history', 'and', 'have', 'be', 'translate', 'into', '67', 'languages', 'the', 'last', 'four', 'book', 'consecutively', 'set', 'record', 'a', 'the', 'fast', 'selling', 'book', 'in', 'history', 'a', 'series', 'of', 'many', 'genre', 'include', 'fantasy', 'and', 'come', 'of', 'age', 'with', 'element', 'of', 'mystery', 'thriller', 'adventure', 'and', 'romance', 'it', 'have', 'many', 'cultural', 'meaning', 'and', 'reference', 'accord', 'to', 'rowling', 'the', 'main', 'theme', 'be', 'death', 'there', 'be', 'also', 'many', 'other', 'theme', 'in', 'the', 'series', 'such', 'a', 'prejudice', 'and', 'corruption', 'the', 'initial', 'major', 'publisher', 'of', 'the', 'book', 'be', 'bloomsbury', 'in', 'the', 'united', 'kingdom', 'and', 'scholastic', 'press', 'in', 'the', 'united', 'state', 'the', 'book', 'have', 'since', 'be', 'publish', 'by', 'many', 'publisher', 'worldwide', 'the', 'book', 'with', 'the', 'seventh', 'book', 'split', 'into', 'two', 'part', 'have', 'be', 'make', 'into', 'an', 'eight', 'part', 'film', 'series', 'by', 'warner', 'bros', 'picture', 'the', 'high', 'grossing', 'film', 'series', 'of', 'all', 'time', 'the', 'series', 'also', 'originate', 'much', 'tie', 'in', 'merchandise', 'make', 'the', 'harry', 'potter', 'brand', 'worth', 'in', 'excess', 'of', '15', 'billion', 'also', 'due', 'to', 'the', 'success', 'of', 'the', 'book', 'and', 'film', 'harry', 'potter', 'have', 'be', 'use', 'for', 'a', 'theme', 'park', 'the', 'wizarding', 'world', 'of', 'harry', 'potter', 'in', 'universal', 'park', 'resort', 's', 'island', 'of', 'adventure']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/jithfernandez/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# creating an empty column for the lemmatized words\n",
        "new_df['Lemm'] = \"\"\n",
        "\n",
        "# function to get the wordnet POS tag and convert to use with lemmatizer\n",
        "def get_wordnet_pos(tags):\n",
        "    if tags.startswith('J'):\n",
        "        return 'a'  # Adjective\n",
        "    elif tags.startswith('V'):\n",
        "        return 'v'  # Verb\n",
        "    elif tags.startswith('N'):\n",
        "        return 'n'  # Noun\n",
        "    elif tags.startswith('R'):\n",
        "        return 'r'  # Adverb\n",
        "    else:\n",
        "        return 'n'\n",
        "\n",
        "\n",
        "for i in range(len(new_df)):\n",
        "    lemma = [lemmatizer.lemmatize(word, pos=get_wordnet_pos(tag)) for word, tag in zip(new_df['tagged_words'][i], new_df['tags'][i])]\n",
        "    new_df.at[i, 'Lemm'] = lemma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
